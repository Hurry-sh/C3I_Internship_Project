{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 》》》**Importing the necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T06:07:45.237085Z",
     "iopub.status.busy": "2025-07-31T06:07:45.236853Z",
     "iopub.status.idle": "2025-07-31T06:08:00.681059Z",
     "shell.execute_reply": "2025-07-31T06:08:00.680266Z",
     "shell.execute_reply.started": "2025-07-31T06:07:45.237068Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-31 06:07:49.383967: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753942069.564567      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753942069.615583      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os, json, joblib, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tensorflow.keras.utils import Sequence, to_categorical, pad_sequences\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, BatchNormalization, Activation, add, MaxPooling1D, Dropout,\n",
    "    Bidirectional, LSTM, GlobalAveragePooling1D, Dense, Multiply, Reshape,\n",
    "    Lambda, Concatenate, GRU, GaussianNoise\n",
    ")\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "import polars as pl\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 》》》**Fix Seed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T06:08:04.978046Z",
     "iopub.status.busy": "2025-07-31T06:08:04.977456Z",
     "iopub.status.idle": "2025-07-31T06:08:04.982550Z",
     "shell.execute_reply": "2025-07-31T06:08:04.981760Z",
     "shell.execute_reply.started": "2025-07-31T06:08:04.978021Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def seed_everything(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    tf.experimental.numpy.random.seed(seed)\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 》》》**Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T06:08:08.284504Z",
     "iopub.status.busy": "2025-07-31T06:08:08.283805Z",
     "iopub.status.idle": "2025-07-31T06:08:08.289406Z",
     "shell.execute_reply": "2025-07-31T06:08:08.288637Z",
     "shell.execute_reply.started": "2025-07-31T06:08:08.284478Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ imports ready · tensorflow 2.18.0\n"
     ]
    }
   ],
   "source": [
    "# (Competition metric will only be imported when TRAINing)\n",
    "TRAIN = True                     # ← set to True when you want to train\n",
    "RAW_DIR = Path(\"/kaggle/input/cmi-detect-behavior-with-sensor-data\")\n",
    "PRETRAINED_DIR = Path(\"/kaggle/input/pretrained-model\")  # used when TRAIN=False\n",
    "EXPORT_DIR = Path(\"./\")                                    # artefacts will be saved here\n",
    "BATCH_SIZE = 64\n",
    "PAD_PERCENTILE = 95\n",
    "LR_INIT = 5e-4\n",
    "WD = 3e-3\n",
    "MIXUP_ALPHA = 0.4\n",
    "EPOCHS = 160\n",
    "PATIENCE = 40\n",
    "\n",
    "\n",
    "print(\"▶ imports ready · tensorflow\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 》》》**Utility Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T06:08:11.840456Z",
     "iopub.status.busy": "2025-07-31T06:08:11.839862Z",
     "iopub.status.idle": "2025-07-31T06:08:11.848253Z",
     "shell.execute_reply": "2025-07-31T06:08:11.847482Z",
     "shell.execute_reply.started": "2025-07-31T06:08:11.840414Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Tensor Manipulations\n",
    "def time_sum(x):\n",
    "    return K.sum(x, axis=1)\n",
    "\n",
    "def squeeze_last_axis(x):\n",
    "    return tf.squeeze(x, axis=-1)\n",
    "\n",
    "def expand_last_axis(x):\n",
    "    return tf.expand_dims(x, axis=-1)\n",
    "\n",
    "def se_block(x, reduction=8):\n",
    "    ch = x.shape[-1]\n",
    "    se = GlobalAveragePooling1D()(x)\n",
    "    se = Dense(ch // reduction, activation='relu')(se)\n",
    "    se = Dense(ch, activation='sigmoid')(se)\n",
    "    se = Reshape((1, ch))(se)\n",
    "    return Multiply()([x, se])\n",
    "\n",
    "# Residual CNN Block with SE\n",
    "def residual_se_cnn_block(x, filters, kernel_size, pool_size=2, drop=0.3, wd=1e-4):\n",
    "    shortcut = x\n",
    "    for _ in range(2):\n",
    "        x = Conv1D(filters, kernel_size, padding='same', use_bias=False,\n",
    "                   kernel_regularizer=l2(wd))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "    x = se_block(x)\n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv1D(filters, 1, padding='same', use_bias=False,\n",
    "                          kernel_regularizer=l2(wd))(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "    x = add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(pool_size)(x)\n",
    "    x = Dropout(drop)(x)\n",
    "    return x\n",
    "\n",
    "def attention_layer(inputs):\n",
    "    score = Dense(1, activation='tanh')(inputs)\n",
    "    score = Lambda(squeeze_last_axis)(score)\n",
    "    weights = Activation('softmax')(score)\n",
    "    weights = Lambda(expand_last_axis)(weights)\n",
    "    context = Multiply()([inputs, weights])\n",
    "    context = Lambda(time_sum)(context)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 》》》**Data Helpers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T06:08:15.795324Z",
     "iopub.status.busy": "2025-07-31T06:08:15.794639Z",
     "iopub.status.idle": "2025-07-31T06:08:15.802409Z",
     "shell.execute_reply": "2025-07-31T06:08:15.801573Z",
     "shell.execute_reply.started": "2025-07-31T06:08:15.795299Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Normalizes and cleans the time series sequence. \n",
    "\n",
    "def preprocess_sequence(df_seq: pd.DataFrame, feature_cols: list[str], scaler: StandardScaler):\n",
    "    mat = df_seq[feature_cols].ffill().bfill().fillna(0).values\n",
    "    return scaler.transform(mat).astype('float32')\n",
    "\n",
    "# MixUp the data argumentation in order to regularize the neural network. \n",
    "\n",
    "class MixupGenerator(Sequence):\n",
    "    def __init__(self, X, y, batch_size, alpha=0.2):\n",
    "        self.X, self.y = X, y\n",
    "        self.batch = batch_size\n",
    "        self.alpha = alpha\n",
    "        self.indices = np.arange(len(X))\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X) / self.batch))\n",
    "    def __getitem__(self, i):\n",
    "        idx = self.indices[i*self.batch:(i+1)*self.batch]\n",
    "        Xb, yb = self.X[idx], self.y[idx]\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        perm = np.random.permutation(len(Xb))\n",
    "        X_mix = lam * Xb + (1-lam) * Xb[perm]\n",
    "        y_mix = lam * yb + (1-lam) * yb[perm]\n",
    "        return X_mix, y_mix\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 》》》**Model Definition - Two Branch Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T06:08:20.688245Z",
     "iopub.status.busy": "2025-07-31T06:08:20.687953Z",
     "iopub.status.idle": "2025-07-31T06:08:23.160445Z",
     "shell.execute_reply": "2025-07-31T06:08:23.159901Z",
     "shell.execute_reply.started": "2025-07-31T06:08:20.688218Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753942101.661833      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "def build_two_branch_model(pad_len, imu_dim, tof_dim, n_classes, wd=1e-4):\n",
    "    inp = Input(shape=(pad_len, imu_dim+tof_dim))\n",
    "    imu = Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    # IMU deep branch\n",
    "    x1 = residual_se_cnn_block(imu, 64, 3, drop=0.1, wd=wd)\n",
    "    x1 = residual_se_cnn_block(x1, 128, 5, drop=0.1, wd=wd)\n",
    "\n",
    "    # TOF/Thermal lighter branch\n",
    "    x2 = Conv1D(64, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(tof)\n",
    "    x2 = BatchNormalization()(x2); x2 = Activation('relu')(x2)\n",
    "    x2 = MaxPooling1D(2)(x2); x2 = Dropout(0.2)(x2)\n",
    "    x2 = Conv1D(128, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(x2)\n",
    "    x2 = BatchNormalization()(x2); x2 = Activation('relu')(x2)\n",
    "    x2 = MaxPooling1D(2)(x2); x2 = Dropout(0.2)(x2)\n",
    "\n",
    "    merged = Concatenate()([x1, x2])\n",
    "\n",
    "    xa = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n",
    "    xb = Bidirectional(GRU(128, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n",
    "    xc = GaussianNoise(0.09)(merged)\n",
    "    xc = Dense(16, activation='elu')(xc)\n",
    "    \n",
    "    x = Concatenate()([xa, xb, xc])\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = attention_layer(x)\n",
    "\n",
    "    for units, drop in [(256, 0.5), (128, 0.3)]:\n",
    "        x = Dense(units, use_bias=False, kernel_regularizer=l2(wd))(x)\n",
    "        x = BatchNormalization()(x); x = Activation('relu')(x)\n",
    "        x = Dropout(drop)(x)\n",
    "\n",
    "    out = Dense(n_classes, activation='softmax', kernel_regularizer=l2(wd))(x)\n",
    "    return Model(inp, out)\n",
    "\n",
    "tmp_model = build_two_branch_model(127,7,325,18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 》》》**Training / Inference Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T06:08:31.724386Z",
     "iopub.status.busy": "2025-07-31T06:08:31.724091Z",
     "iopub.status.idle": "2025-07-31T06:21:33.587975Z",
     "shell.execute_reply": "2025-07-31T06:21:33.587206Z",
     "shell.execute_reply.started": "2025-07-31T06:08:31.724364Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ TRAIN MODE – loading dataset …\n",
      "  Calculating engineered IMU features (magnitude, angle)...\n",
      "  Calculating engineered IMU derivatives (jerk, angular velocity)...\n",
      "  IMU (incl. engineered & derivatives) 11 | THM + Aggregated TOF 25 | total 36 features\n",
      "  Building sequences with aggregated TOF and preparing data for scaler...\n",
      "  Fitting StandardScaler...\n",
      "  Scaling and padding sequences...\n",
      "  Splitting data and preparing for training...\n",
      "  Starting model training...\n",
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753942284.223024      95 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m114/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.1288 - loss: 9.6306"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-31 06:11:31.122272: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 51ms/step - accuracy: 0.1297 - loss: 9.6183 - val_accuracy: 0.3640 - val_loss: 7.6035\n",
      "Epoch 2/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.2731 - loss: 7.2963 - val_accuracy: 0.4338 - val_loss: 5.9587\n",
      "Epoch 3/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.3273 - loss: 5.9918 - val_accuracy: 0.4681 - val_loss: 5.0041\n",
      "Epoch 4/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.3919 - loss: 5.1216 - val_accuracy: 0.5000 - val_loss: 4.3272\n",
      "Epoch 5/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.4129 - loss: 4.6420 - val_accuracy: 0.5037 - val_loss: 3.9037\n",
      "Epoch 6/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.4477 - loss: 4.1739 - val_accuracy: 0.5453 - val_loss: 3.5924\n",
      "Epoch 7/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.4879 - loss: 3.8546 - val_accuracy: 0.5600 - val_loss: 3.3447\n",
      "Epoch 8/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.4864 - loss: 3.6232 - val_accuracy: 0.5368 - val_loss: 3.2365\n",
      "Epoch 9/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.4996 - loss: 3.4985 - val_accuracy: 0.5797 - val_loss: 3.0236\n",
      "Epoch 10/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5253 - loss: 3.3901 - val_accuracy: 0.5956 - val_loss: 2.9266\n",
      "Epoch 11/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5388 - loss: 3.2607 - val_accuracy: 0.6005 - val_loss: 2.8420\n",
      "Epoch 12/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5408 - loss: 3.2406 - val_accuracy: 0.6042 - val_loss: 2.7920\n",
      "Epoch 13/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5547 - loss: 3.1443 - val_accuracy: 0.6127 - val_loss: 2.7756\n",
      "Epoch 14/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5538 - loss: 3.1354 - val_accuracy: 0.6152 - val_loss: 2.7618\n",
      "Epoch 15/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5654 - loss: 3.0717 - val_accuracy: 0.5527 - val_loss: 2.9074\n",
      "Epoch 16/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5111 - loss: 3.1938 - val_accuracy: 0.5539 - val_loss: 2.7618\n",
      "Epoch 17/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.4975 - loss: 3.0271 - val_accuracy: 0.5919 - val_loss: 2.5143\n",
      "Epoch 18/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5380 - loss: 2.7881 - val_accuracy: 0.5870 - val_loss: 2.4043\n",
      "Epoch 19/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5302 - loss: 2.6430 - val_accuracy: 0.6054 - val_loss: 2.2273\n",
      "Epoch 20/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5484 - loss: 2.5724 - val_accuracy: 0.6115 - val_loss: 2.1701\n",
      "Epoch 21/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5428 - loss: 2.5355 - val_accuracy: 0.6164 - val_loss: 2.0888\n",
      "Epoch 22/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5702 - loss: 2.4007 - val_accuracy: 0.6054 - val_loss: 2.0815\n",
      "Epoch 23/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5577 - loss: 2.4178 - val_accuracy: 0.6164 - val_loss: 1.9520\n",
      "Epoch 24/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5827 - loss: 2.2081 - val_accuracy: 0.6029 - val_loss: 1.9654\n",
      "Epoch 25/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5916 - loss: 2.1653 - val_accuracy: 0.6201 - val_loss: 1.8727\n",
      "Epoch 26/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5747 - loss: 2.2186 - val_accuracy: 0.6287 - val_loss: 1.8325\n",
      "Epoch 27/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6018 - loss: 2.1088 - val_accuracy: 0.6409 - val_loss: 1.8138\n",
      "Epoch 28/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6094 - loss: 2.1430 - val_accuracy: 0.6471 - val_loss: 1.7891\n",
      "Epoch 29/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6009 - loss: 2.0261 - val_accuracy: 0.6544 - val_loss: 1.7263\n",
      "Epoch 30/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6254 - loss: 2.0667 - val_accuracy: 0.6483 - val_loss: 1.7661\n",
      "Epoch 31/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6321 - loss: 2.0338 - val_accuracy: 0.6777 - val_loss: 1.6844\n",
      "Epoch 32/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6235 - loss: 1.9992 - val_accuracy: 0.6581 - val_loss: 1.6503\n",
      "Epoch 33/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6293 - loss: 2.0691 - val_accuracy: 0.6532 - val_loss: 1.6409\n",
      "Epoch 34/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6445 - loss: 1.9467 - val_accuracy: 0.6936 - val_loss: 1.5835\n",
      "Epoch 35/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6711 - loss: 1.8575 - val_accuracy: 0.6801 - val_loss: 1.5928\n",
      "Epoch 36/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6612 - loss: 1.9043 - val_accuracy: 0.6691 - val_loss: 1.5965\n",
      "Epoch 37/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6729 - loss: 1.8986 - val_accuracy: 0.7194 - val_loss: 1.5315\n",
      "Epoch 38/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6775 - loss: 1.8898 - val_accuracy: 0.7132 - val_loss: 1.5214\n",
      "Epoch 39/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7140 - loss: 1.7628 - val_accuracy: 0.7206 - val_loss: 1.5054\n",
      "Epoch 40/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6974 - loss: 1.8517 - val_accuracy: 0.7120 - val_loss: 1.5048\n",
      "Epoch 41/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7139 - loss: 1.8050 - val_accuracy: 0.7279 - val_loss: 1.4951\n",
      "Epoch 42/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.6878 - loss: 1.8902 - val_accuracy: 0.7169 - val_loss: 1.4969\n",
      "Epoch 43/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7096 - loss: 1.8161 - val_accuracy: 0.7181 - val_loss: 1.4899\n",
      "Epoch 44/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7065 - loss: 1.8636 - val_accuracy: 0.7157 - val_loss: 1.4894\n",
      "Epoch 45/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7197 - loss: 1.7519 - val_accuracy: 0.5662 - val_loss: 1.9706\n",
      "Epoch 46/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5835 - loss: 2.0109 - val_accuracy: 0.6189 - val_loss: 1.7521\n",
      "Epoch 47/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5754 - loss: 2.0548 - val_accuracy: 0.6360 - val_loss: 1.6683\n",
      "Epoch 48/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6060 - loss: 2.0133 - val_accuracy: 0.6311 - val_loss: 1.7032\n",
      "Epoch 49/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6172 - loss: 1.9277 - val_accuracy: 0.6373 - val_loss: 1.7508\n",
      "Epoch 50/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6229 - loss: 1.9507 - val_accuracy: 0.6630 - val_loss: 1.6961\n",
      "Epoch 51/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6540 - loss: 1.8812 - val_accuracy: 0.6703 - val_loss: 1.6434\n",
      "Epoch 52/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6391 - loss: 1.8801 - val_accuracy: 0.6250 - val_loss: 1.7029\n",
      "Epoch 53/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6500 - loss: 1.8488 - val_accuracy: 0.6409 - val_loss: 1.6613\n",
      "Epoch 54/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6278 - loss: 1.9750 - val_accuracy: 0.6679 - val_loss: 1.6348\n",
      "Epoch 55/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6520 - loss: 1.8845 - val_accuracy: 0.6716 - val_loss: 1.5975\n",
      "Epoch 56/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6511 - loss: 1.8599 - val_accuracy: 0.6385 - val_loss: 1.6702\n",
      "Epoch 57/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6615 - loss: 1.8199 - val_accuracy: 0.6728 - val_loss: 1.5663\n",
      "Epoch 58/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6491 - loss: 1.8654 - val_accuracy: 0.6201 - val_loss: 1.7145\n",
      "Epoch 59/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6351 - loss: 1.9067 - val_accuracy: 0.6826 - val_loss: 1.5572\n",
      "Epoch 60/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6678 - loss: 1.8578 - val_accuracy: 0.6973 - val_loss: 1.5296\n",
      "Epoch 61/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6739 - loss: 1.8548 - val_accuracy: 0.6458 - val_loss: 1.6598\n",
      "Epoch 62/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6525 - loss: 1.7958 - val_accuracy: 0.6789 - val_loss: 1.5457\n",
      "Epoch 63/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6761 - loss: 1.7185 - val_accuracy: 0.6863 - val_loss: 1.5369\n",
      "Epoch 64/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6625 - loss: 1.8417 - val_accuracy: 0.7010 - val_loss: 1.5097\n",
      "Epoch 65/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7000 - loss: 1.7415 - val_accuracy: 0.7230 - val_loss: 1.4834\n",
      "Epoch 66/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6817 - loss: 1.7838 - val_accuracy: 0.6924 - val_loss: 1.4851\n",
      "Epoch 67/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6677 - loss: 1.8234 - val_accuracy: 0.6838 - val_loss: 1.5333\n",
      "Epoch 68/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7015 - loss: 1.7614 - val_accuracy: 0.6850 - val_loss: 1.4917\n",
      "Epoch 69/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7020 - loss: 1.7774 - val_accuracy: 0.7047 - val_loss: 1.4926\n",
      "Epoch 70/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6725 - loss: 1.8981 - val_accuracy: 0.6850 - val_loss: 1.5341\n",
      "Epoch 71/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7067 - loss: 1.7430 - val_accuracy: 0.7010 - val_loss: 1.4625\n",
      "Epoch 72/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6995 - loss: 1.8199 - val_accuracy: 0.6998 - val_loss: 1.5028\n",
      "Epoch 73/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7137 - loss: 1.7244 - val_accuracy: 0.6483 - val_loss: 1.5556\n",
      "Epoch 74/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7099 - loss: 1.7063 - val_accuracy: 0.7230 - val_loss: 1.3894\n",
      "Epoch 75/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7133 - loss: 1.6803 - val_accuracy: 0.7353 - val_loss: 1.4147\n",
      "Epoch 76/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7294 - loss: 1.6287 - val_accuracy: 0.7402 - val_loss: 1.3995\n",
      "Epoch 77/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7462 - loss: 1.6450 - val_accuracy: 0.7096 - val_loss: 1.3977\n",
      "Epoch 78/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7178 - loss: 1.7330 - val_accuracy: 0.6924 - val_loss: 1.4670\n",
      "Epoch 79/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7184 - loss: 1.7524 - val_accuracy: 0.6985 - val_loss: 1.4704\n",
      "Epoch 80/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7422 - loss: 1.6804 - val_accuracy: 0.7328 - val_loss: 1.3739\n",
      "Epoch 81/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7474 - loss: 1.6359 - val_accuracy: 0.7451 - val_loss: 1.3828\n",
      "Epoch 82/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7455 - loss: 1.6544 - val_accuracy: 0.7353 - val_loss: 1.3633\n",
      "Epoch 83/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7470 - loss: 1.6448 - val_accuracy: 0.7426 - val_loss: 1.3865\n",
      "Epoch 84/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7395 - loss: 1.6684 - val_accuracy: 0.7414 - val_loss: 1.3472\n",
      "Epoch 85/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7645 - loss: 1.5763 - val_accuracy: 0.7451 - val_loss: 1.3327\n",
      "Epoch 86/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7826 - loss: 1.4957 - val_accuracy: 0.7500 - val_loss: 1.3379\n",
      "Epoch 87/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7747 - loss: 1.5900 - val_accuracy: 0.7426 - val_loss: 1.3481\n",
      "Epoch 88/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7808 - loss: 1.5821 - val_accuracy: 0.7488 - val_loss: 1.3233\n",
      "Epoch 89/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8010 - loss: 1.5346 - val_accuracy: 0.7819 - val_loss: 1.2918\n",
      "Epoch 90/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7936 - loss: 1.5453 - val_accuracy: 0.7402 - val_loss: 1.3164\n",
      "Epoch 91/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7895 - loss: 1.5637 - val_accuracy: 0.7586 - val_loss: 1.2887\n",
      "Epoch 92/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.8040 - loss: 1.5266 - val_accuracy: 0.7598 - val_loss: 1.2920\n",
      "Epoch 93/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.8007 - loss: 1.5457 - val_accuracy: 0.7659 - val_loss: 1.2826\n",
      "Epoch 94/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7963 - loss: 1.5937 - val_accuracy: 0.7684 - val_loss: 1.2862\n",
      "Epoch 95/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7958 - loss: 1.5628 - val_accuracy: 0.7721 - val_loss: 1.2909\n",
      "Epoch 96/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7802 - loss: 1.5841 - val_accuracy: 0.7757 - val_loss: 1.2865\n",
      "Epoch 97/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7871 - loss: 1.5909 - val_accuracy: 0.7770 - val_loss: 1.2757\n",
      "Epoch 98/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7972 - loss: 1.5456 - val_accuracy: 0.7696 - val_loss: 1.2726\n",
      "Epoch 99/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8207 - loss: 1.4910 - val_accuracy: 0.7831 - val_loss: 1.2611\n",
      "Epoch 100/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8074 - loss: 1.5349 - val_accuracy: 0.7721 - val_loss: 1.2724\n",
      "Epoch 101/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.8210 - loss: 1.5203 - val_accuracy: 0.7831 - val_loss: 1.2692\n",
      "Epoch 102/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.8076 - loss: 1.5584 - val_accuracy: 0.7757 - val_loss: 1.2749\n",
      "Epoch 103/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8350 - loss: 1.4824 - val_accuracy: 0.7782 - val_loss: 1.2715\n",
      "Epoch 104/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8023 - loss: 1.5341 - val_accuracy: 0.7770 - val_loss: 1.2700\n",
      "Epoch 105/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7547 - loss: 1.5840 - val_accuracy: 0.6777 - val_loss: 1.5808\n",
      "Epoch 106/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6554 - loss: 1.8381 - val_accuracy: 0.6900 - val_loss: 1.5704\n",
      "Epoch 107/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7127 - loss: 1.7381 - val_accuracy: 0.6054 - val_loss: 1.8205\n",
      "Epoch 108/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.6750 - loss: 1.8556 - val_accuracy: 0.6642 - val_loss: 1.5896\n",
      "Epoch 109/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.6839 - loss: 1.8467 - val_accuracy: 0.6863 - val_loss: 1.5356\n",
      "Epoch 110/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6844 - loss: 1.7901 - val_accuracy: 0.6961 - val_loss: 1.5037\n",
      "Epoch 111/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6784 - loss: 1.9016 - val_accuracy: 0.7047 - val_loss: 1.4923\n",
      "Epoch 112/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6951 - loss: 1.7734 - val_accuracy: 0.7010 - val_loss: 1.5145\n",
      "Epoch 113/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7206 - loss: 1.6696 - val_accuracy: 0.6826 - val_loss: 1.5426\n",
      "Epoch 114/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7103 - loss: 1.7810 - val_accuracy: 0.6789 - val_loss: 1.5109\n",
      "Epoch 115/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7155 - loss: 1.7456 - val_accuracy: 0.7083 - val_loss: 1.5620\n",
      "Epoch 116/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7411 - loss: 1.6436 - val_accuracy: 0.6716 - val_loss: 1.5817\n",
      "Epoch 117/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7004 - loss: 1.8237 - val_accuracy: 0.7108 - val_loss: 1.4938\n",
      "Epoch 118/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7208 - loss: 1.6758 - val_accuracy: 0.7157 - val_loss: 1.4739\n",
      "Epoch 119/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7240 - loss: 1.7136 - val_accuracy: 0.6998 - val_loss: 1.5213\n",
      "Epoch 120/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7106 - loss: 1.7857 - val_accuracy: 0.7071 - val_loss: 1.5068\n",
      "Epoch 121/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6953 - loss: 1.8215 - val_accuracy: 0.6985 - val_loss: 1.5135\n",
      "Epoch 122/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6993 - loss: 1.7581 - val_accuracy: 0.6936 - val_loss: 1.5228\n",
      "Epoch 123/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7246 - loss: 1.7250 - val_accuracy: 0.7071 - val_loss: 1.5405\n",
      "Epoch 124/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7207 - loss: 1.7622 - val_accuracy: 0.7022 - val_loss: 1.5275\n",
      "Epoch 125/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7427 - loss: 1.6479 - val_accuracy: 0.7132 - val_loss: 1.5153\n",
      "Epoch 126/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7290 - loss: 1.7251 - val_accuracy: 0.6961 - val_loss: 1.5167\n",
      "Epoch 127/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7265 - loss: 1.7076 - val_accuracy: 0.7194 - val_loss: 1.5064\n",
      "Epoch 128/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7287 - loss: 1.7452 - val_accuracy: 0.6900 - val_loss: 1.5149\n",
      "Epoch 129/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7649 - loss: 1.6267 - val_accuracy: 0.6850 - val_loss: 1.5419\n",
      "Epoch 130/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7206 - loss: 1.7695 - val_accuracy: 0.6777 - val_loss: 1.5722\n",
      "Epoch 131/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7404 - loss: 1.7713 - val_accuracy: 0.7181 - val_loss: 1.4972\n",
      "Epoch 132/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7351 - loss: 1.6913 - val_accuracy: 0.6581 - val_loss: 1.6606\n",
      "Epoch 133/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7486 - loss: 1.6790 - val_accuracy: 0.7194 - val_loss: 1.4998\n",
      "Epoch 134/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7365 - loss: 1.7382 - val_accuracy: 0.7022 - val_loss: 1.5068\n",
      "Epoch 135/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7420 - loss: 1.6677 - val_accuracy: 0.6961 - val_loss: 1.5639\n",
      "Epoch 136/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7483 - loss: 1.6714 - val_accuracy: 0.7157 - val_loss: 1.5093\n",
      "Epoch 137/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7401 - loss: 1.7079 - val_accuracy: 0.7230 - val_loss: 1.4826\n",
      "Epoch 138/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.7324 - loss: 1.7240 - val_accuracy: 0.7145 - val_loss: 1.4820\n",
      "Epoch 139/160\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7369 - loss: 1.7146 - val_accuracy: 0.7194 - val_loss: 1.4633\n",
      "Epoch 139: early stopping\n",
      "Restoring model weights from the end of the best epoch: 99.\n",
      "✔ Training done – artefacts saved in .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-31 06:21:31.744836: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step\n",
      "Hold‑out H‑F1 = 0.866\n"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    print(\"▶ TRAIN MODE – loading dataset …\")\n",
    "    df = pd.read_csv(RAW_DIR / \"train.csv\")\n",
    "\n",
    "    train_dem_df = pd.read_csv(RAW_DIR / \"train_demographics.csv\")\n",
    "    df_for_groups = pd.merge(df.copy(), train_dem_df, on='subject', how='left')\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    df['gesture_int'] = le.fit_transform(df['gesture'])\n",
    "    np.save(EXPORT_DIR / \"gesture_classes.npy\", le.classes_)\n",
    "    gesture_classes = le.classes_\n",
    "\n",
    "    print(\"  Calculating engineered IMU features (magnitude, angle)...\")\n",
    "    df['acc_mag'] = np.sqrt(df['acc_x']**2 + df['acc_y']**2 + df['acc_z']**2)\n",
    "    df['rot_angle'] = 2 * np.arccos(df['rot_w'].clip(-1, 1))\n",
    "    \n",
    "    print(\"  Calculating engineered IMU derivatives (jerk, angular velocity)...\")\n",
    "    df['acc_mag_jerk'] = df.groupby('sequence_id')['acc_mag'].diff().fillna(0)\n",
    "    df['rot_angle_vel'] = df.groupby('sequence_id')['rot_angle'].diff().fillna(0)\n",
    "\n",
    "    meta_cols = {'gesture', 'gesture_int', 'sequence_type', 'behavior', 'orientation',\n",
    "                 'row_id', 'subject', 'phase', 'sequence_id', 'sequence_counter'}\n",
    "\n",
    "    imu_cols = [c for c in df.columns if c.startswith('acc_') and c not in ['acc_mag', 'acc_mag_jerk']]\n",
    "    imu_cols.extend([c for c in df.columns if c.startswith('rot_') and c not in ['rot_angle', 'rot_angle_vel']])\n",
    "    imu_cols.extend(['acc_mag', 'rot_angle', 'acc_mag_jerk', 'rot_angle_vel'])\n",
    "\n",
    "    thm_cols_original = [c for c in df.columns if c.startswith('thm_')]\n",
    "    \n",
    "    tof_aggregated_cols_template = []\n",
    "    for i in range(1, 6):\n",
    "        tof_aggregated_cols_template.extend([f'tof_{i}_mean', f'tof_{i}_std', f'tof_{i}_min', f'tof_{i}_max'])\n",
    "\n",
    "    final_feature_cols = imu_cols + thm_cols_original + tof_aggregated_cols_template\n",
    "    imu_dim_final = len(imu_cols)\n",
    "    tof_thm_aggregated_dim_final = len(thm_cols_original) + len(tof_aggregated_cols_template)\n",
    "    \n",
    "    print(f\"  IMU (incl. engineered & derivatives) {imu_dim_final} | THM + Aggregated TOF {tof_thm_aggregated_dim_final} | total {len(final_feature_cols)} features\")\n",
    "    np.save(EXPORT_DIR / \"feature_cols.npy\", np.array(final_feature_cols))\n",
    "\n",
    "    print(\"  Building sequences with aggregated TOF and preparing data for scaler...\")\n",
    "    seq_gp = df.groupby('sequence_id') \n",
    "    \n",
    "    all_steps_for_scaler_list = []\n",
    "    X_list_unscaled, y_list_int_for_stratify, lens = [], [], [] \n",
    "\n",
    "    for seq_id, seq_df_orig in seq_gp:\n",
    "        seq_df = seq_df_orig.copy()\n",
    "\n",
    "        for i in range(1, 6):\n",
    "            pixel_cols_tof = [f\"tof_{i}_v{p}\" for p in range(64)]\n",
    "            tof_sensor_data = seq_df[pixel_cols_tof].replace(-1, np.nan)\n",
    "            seq_df[f'tof_{i}_mean'] = tof_sensor_data.mean(axis=1)\n",
    "            seq_df[f'tof_{i}_std']  = tof_sensor_data.std(axis=1)\n",
    "            seq_df[f'tof_{i}_min']  = tof_sensor_data.min(axis=1)\n",
    "            seq_df[f'tof_{i}_max']  = tof_sensor_data.max(axis=1)\n",
    "        \n",
    "        mat_unscaled = seq_df[final_feature_cols].ffill().bfill().fillna(0).values.astype('float32')\n",
    "        \n",
    "        all_steps_for_scaler_list.append(mat_unscaled)\n",
    "        X_list_unscaled.append(mat_unscaled)\n",
    "        y_list_int_for_stratify.append(seq_df['gesture_int'].iloc[0])\n",
    "        lens.append(len(mat_unscaled))\n",
    "\n",
    "    print(\"  Fitting StandardScaler...\")\n",
    "    all_steps_concatenated = np.concatenate(all_steps_for_scaler_list, axis=0)\n",
    "    scaler = StandardScaler().fit(all_steps_concatenated)\n",
    "    joblib.dump(scaler, EXPORT_DIR / \"scaler.pkl\")\n",
    "    del all_steps_for_scaler_list, all_steps_concatenated\n",
    "\n",
    "    print(\"  Scaling and padding sequences...\")\n",
    "    X_scaled_list = [scaler.transform(x_seq) for x_seq in X_list_unscaled]\n",
    "    del X_list_unscaled\n",
    "\n",
    "    pad_len = int(np.percentile(lens, PAD_PERCENTILE))\n",
    "    np.save(EXPORT_DIR / \"sequence_maxlen.npy\", pad_len)\n",
    "    \n",
    "    X = pad_sequences(X_scaled_list, maxlen=pad_len, padding='post', truncating='post', dtype='float32')\n",
    "    del X_scaled_list\n",
    "    \n",
    "    y_int_for_stratify = np.array(y_list_int_for_stratify)\n",
    "    y = to_categorical(y_int_for_stratify, num_classes=len(le.classes_))\n",
    "\n",
    "    print(\"  Splitting data and preparing for training...\")\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.1, random_state=82, stratify=y_int_for_stratify)\n",
    "\n",
    "    cw_vals = compute_class_weight('balanced', classes=np.arange(len(le.classes_)), y=y_int_for_stratify)\n",
    "    class_weight = dict(enumerate(cw_vals))\n",
    "\n",
    "    model = build_two_branch_model(pad_len, imu_dim_final, tof_thm_aggregated_dim_final, len(le.classes_), wd=WD)\n",
    "    \n",
    "    steps = len(X_tr) // BATCH_SIZE\n",
    "    lr_sched = tf.keras.optimizers.schedules.CosineDecayRestarts(5e-4, first_decay_steps=15 * steps) \n",
    "    \n",
    "    model.compile(optimizer=Adam(lr_sched),\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    train_gen = MixupGenerator(X_tr, y_tr, batch_size=BATCH_SIZE, alpha=MIXUP_ALPHA)\n",
    "    cb = EarlyStopping(patience=PATIENCE, restore_best_weights=True, verbose=1, monitor='val_accuracy', mode='max')\n",
    "    \n",
    "    print(\"  Starting model training...\")\n",
    "    model.fit(train_gen, epochs=EPOCHS, validation_data=(X_val, y_val),\n",
    "              class_weight=class_weight, callbacks=[cb], verbose=1)\n",
    "\n",
    "    model.save(EXPORT_DIR / \"gesture_two_branch_mixup.h5\")\n",
    "    print(\"✔ Training done – artefacts saved in\", EXPORT_DIR)\n",
    "\n",
    "    from cmi_2025_metric_copy_for_import import CompetitionMetric\n",
    "    preds_val = model.predict(X_val).argmax(1)\n",
    "    true_val_int  = y_val.argmax(1)\n",
    "    \n",
    "    h_f1 = CompetitionMetric().calculate_hierarchical_f1(\n",
    "        pd.DataFrame({'gesture': le.classes_[true_val_int]}),\n",
    "        pd.DataFrame({'gesture': le.classes_[preds_val]}))\n",
    "    print(\"Hold‑out H‑F1 =\", round(h_f1, 4))\n",
    "\n",
    "else:\n",
    "    print(\"▶ INFERENCE MODE – loading artefacts from\", PRETRAINED_DIR)\n",
    "    final_feature_cols = np.load(PRETRAINED_DIR / \"feature_cols.npy\", allow_pickle=True).tolist()\n",
    "    pad_len        = int(np.load(PRETRAINED_DIR / \"sequence_maxlen.npy\"))\n",
    "    scaler         = joblib.load(PRETRAINED_DIR / \"scaler.pkl\")\n",
    "    gesture_classes = np.load(PRETRAINED_DIR / \"gesture_classes.npy\", allow_pickle=True)\n",
    "\n",
    "    temp_imu_cols = [c for c in final_feature_cols if c.startswith('acc_') or c.startswith('rot_')]\n",
    "    imu_dim_final = len(temp_imu_cols)\n",
    "    tof_thm_aggregated_dim_final = len(final_feature_cols) - imu_dim_final\n",
    "\n",
    "    custom_objs = {\n",
    "        'time_sum': time_sum,\n",
    "        'squeeze_last_axis': squeeze_last_axis,\n",
    "        'expand_last_axis': expand_last_axis,\n",
    "        'se_block': se_block,\n",
    "        'residual_se_cnn_block': residual_se_cnn_block,\n",
    "        'attention_layer': attention_layer,\n",
    "    }\n",
    "    model = load_model(PRETRAINED_DIR / \"gesture_two_branch_mixup.h5\",\n",
    "                       compile=False, custom_objects=custom_objs)\n",
    "    print(\"  Model, scaler, feature_cols, pad_len loaded – ready for evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 》》》**Predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T06:21:48.955123Z",
     "iopub.status.busy": "2025-07-31T06:21:48.954826Z",
     "iopub.status.idle": "2025-07-31T06:21:48.962799Z",
     "shell.execute_reply": "2025-07-31T06:21:48.961812Z",
     "shell.execute_reply.started": "2025-07-31T06:21:48.955101Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "    df_seq = sequence.to_pandas()\n",
    "\n",
    "    df_seq['acc_mag'] = np.sqrt(df_seq['acc_x']**2 + df_seq['acc_y']**2 + df_seq['acc_z']**2)\n",
    "    df_seq['rot_angle'] = 2 * np.arccos(df_seq['rot_w'].clip(-1, 1))\n",
    "    df_seq['acc_mag_jerk'] = df_seq['acc_mag'].diff().fillna(0)\n",
    "    df_seq['rot_angle_vel'] = df_seq['rot_angle'].diff().fillna(0)\n",
    "    \n",
    "    for i in range(1, 6): \n",
    "        pixel_cols_tof = [f\"tof_{i}_v{p}\" for p in range(64)]\n",
    "        tof_sensor_data = df_seq[pixel_cols_tof].replace(-1, np.nan)\n",
    "        \n",
    "        df_seq[f'tof_{i}_mean'] = tof_sensor_data.mean(axis=1)\n",
    "        df_seq[f'tof_{i}_std']  = tof_sensor_data.std(axis=1)\n",
    "        df_seq[f'tof_{i}_min']  = tof_sensor_data.min(axis=1)\n",
    "        df_seq[f'tof_{i}_max']  = tof_sensor_data.max(axis=1)\n",
    "        \n",
    "    df_seq_reordered = pd.DataFrame(columns=final_feature_cols)\n",
    "    for col in final_feature_cols:\n",
    "        if col in df_seq.columns:\n",
    "            df_seq_reordered[col] = df_seq[col]\n",
    "\n",
    "    mat_unscaled = df_seq_reordered.ffill().bfill().fillna(0).values.astype('float32')\n",
    "    \n",
    "    mat_scaled = scaler.transform(mat_unscaled)\n",
    "    \n",
    "    pad_input = pad_sequences([mat_scaled], maxlen=pad_len, padding='post', truncating='post', dtype='float32')\n",
    "    \n",
    "    idx = int(model.predict(pad_input, verbose=0).argmax(1)[0])\n",
    "    return str(gesture_classes[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 》》》**Submit Inference server**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T12:55:14.777634Z",
     "iopub.status.busy": "2025-06-14T12:55:14.777453Z",
     "iopub.status.idle": "2025-06-14T12:55:16.607366Z",
     "shell.execute_reply": "2025-06-14T12:55:16.60677Z",
     "shell.execute_reply.started": "2025-06-14T12:55:14.77762Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import kaggle_evaluation.cmi_inference_server\n",
    "inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        data_paths=(\n",
    "            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv',\n",
    "            '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv',\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "sourceId": 102335,
     "sourceType": "competition"
    },
    {
     "sourceId": 242954653,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
